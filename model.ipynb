{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:23<00:00, 1.12MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 111kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:03<00:00, 1.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.47MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "EPOCH 1:\n",
      "  batch 1000 loss: 2.0769065489172935\n",
      "  batch 2000 loss: 0.8892503114230931\n",
      "  batch 3000 loss: 0.7053988220626488\n",
      "  batch 4000 loss: 0.6461607569096377\n",
      "  batch 5000 loss: 0.601860106823966\n",
      "  batch 6000 loss: 0.5402796836183407\n",
      "  batch 7000 loss: 0.522783867732156\n",
      "  batch 8000 loss: 0.5056687665043864\n",
      "  batch 9000 loss: 0.5237707058782689\n",
      "  batch 10000 loss: 0.4820752427417319\n",
      "  batch 11000 loss: 0.4484311608923599\n",
      "  batch 12000 loss: 0.4652861777331564\n",
      "  batch 13000 loss: 0.4447609548387409\n",
      "  batch 14000 loss: 0.42767637387115975\n",
      "  batch 15000 loss: 0.4354151883643062\n",
      "LOSS train 0.4354151883643062 valid 0.42476552724838257\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.4010855246403953\n",
      "  batch 2000 loss: 0.41905513071303724\n",
      "  batch 3000 loss: 0.4217957528201514\n",
      "  batch 4000 loss: 0.396095661353771\n",
      "  batch 5000 loss: 0.38610139728739157\n",
      "  batch 6000 loss: 0.36183211884758204\n",
      "  batch 7000 loss: 0.35234136047953507\n",
      "  batch 8000 loss: 0.3656286267005489\n",
      "  batch 9000 loss: 0.3811821336087305\n",
      "  batch 10000 loss: 0.37333873867281364\n",
      "  batch 11000 loss: 0.34964159460633526\n",
      "  batch 12000 loss: 0.34414742623548955\n",
      "  batch 13000 loss: 0.3651558385734679\n",
      "  batch 14000 loss: 0.37614454665151426\n",
      "  batch 15000 loss: 0.3435057957212266\n",
      "LOSS train 0.3435057957212266 valid 0.36733126640319824\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.3316048779081175\n",
      "  batch 2000 loss: 0.33157638752250934\n",
      "  batch 3000 loss: 0.32642996963884796\n",
      "  batch 4000 loss: 0.3161444011505228\n",
      "  batch 5000 loss: 0.3405065164351763\n",
      "  batch 6000 loss: 0.32336102838604713\n",
      "  batch 7000 loss: 0.3180109380005779\n",
      "  batch 8000 loss: 0.32415788928768596\n",
      "  batch 9000 loss: 0.3172023558057335\n",
      "  batch 10000 loss: 0.3231623447794118\n",
      "  batch 11000 loss: 0.3381122322493611\n",
      "  batch 12000 loss: 0.3259815531727654\n",
      "  batch 13000 loss: 0.2946789999487519\n",
      "  batch 14000 loss: 0.2956741908634285\n",
      "  batch 15000 loss: 0.3231010065596783\n",
      "LOSS train 0.3231010065596783 valid 0.3430574834346771\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.29178183239710054\n",
      "  batch 2000 loss: 0.28906506208764404\n",
      "  batch 3000 loss: 0.3016143098917528\n",
      "  batch 4000 loss: 0.29413780806254364\n",
      "  batch 5000 loss: 0.3074712639734207\n",
      "  batch 6000 loss: 0.2702217922042182\n",
      "  batch 7000 loss: 0.2898614480924516\n",
      "  batch 8000 loss: 0.299889696652448\n",
      "  batch 9000 loss: 0.3039408239731565\n",
      "  batch 10000 loss: 0.29938545367282493\n",
      "  batch 11000 loss: 0.2984956215062339\n",
      "  batch 12000 loss: 0.2952186174687522\n",
      "  batch 13000 loss: 0.29253391317223576\n",
      "  batch 14000 loss: 0.2802117288462614\n",
      "  batch 15000 loss: 0.28553485891575836\n",
      "LOSS train 0.28553485891575836 valid 0.34310582280158997\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.259045782362482\n",
      "  batch 2000 loss: 0.2689160452120666\n",
      "  batch 3000 loss: 0.28628955826980385\n",
      "  batch 4000 loss: 0.2918819218436256\n",
      "  batch 5000 loss: 0.25132712184593037\n",
      "  batch 6000 loss: 0.2684881750943168\n",
      "  batch 7000 loss: 0.27450973165390496\n",
      "  batch 8000 loss: 0.28469644725948456\n",
      "  batch 9000 loss: 0.27850272545550253\n",
      "  batch 10000 loss: 0.2807974032495886\n",
      "  batch 11000 loss: 0.27232089409739274\n",
      "  batch 12000 loss: 0.2774537005233251\n",
      "  batch 13000 loss: 0.2626962062532848\n",
      "  batch 14000 loss: 0.27247053941853666\n",
      "  batch 15000 loss: 0.27587914746142633\n",
      "LOSS train 0.27587914746142633 valid 0.3086117208003998\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 데이터셋 로드\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader 클래스로 batch 훈련 및 검증 데이터 생성\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# 최종 라벨링\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 2개의 합성곱-풀링 계층과 3개의 완전 연결 계층으로 구성된 LeNet-5 변형 모델\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d07ea0762118>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_model.load_state_dict(torch.load(PATH))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'model_{}_{}'.format(timestamp, epoch_number - 1)\n",
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image saved as 'test_image.png' with label: 9\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "test_set = datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Save a random image from the test dataset\n",
    "index = 0  # Change index for different images\n",
    "image, label = test_set[index]\n",
    "pil_image = transforms.ToPILImage()(image)\n",
    "pil_image.save(\"./examples/test_image.png\")\n",
    "print(f\"Test image saved as 'test_image.png' with label: {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
